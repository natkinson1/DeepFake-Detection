{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Image data\n",
    "\n",
    "This Jupyter Notebook shows the code which was used to extract frames from the video data. These frames where then added to a separate image data set which was used to train the improved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import torch\n",
    "import face_detector\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import random\n",
    "from PIL import Image\n",
    "import albumentations as alb\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the names of every video file in the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vll_real = glob.glob(\"./videos/train_sample_videos/real/*.mp4\")\n",
    "vll_fake = glob.glob(\"./videos/train_sample_videos/fake/*.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply random transforms to each extracted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.RandomGrayscale(p=0.1),\n",
    "                                      transforms.RandomRotation(20),\n",
    "                                      transforms.RandomAffine(5),\n",
    "                                      transforms.ColorJitter(brightness=0, contrast=1, saturation=0, hue=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = face_detector.random_frame_selector(vll_real[0])\n",
    "face = face_detector.face_cropper(frame)\n",
    "\n",
    "face = data_transforms(face)\n",
    "\n",
    "plt.imshow(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cropped_image(source, label_type):\n",
    "    \n",
    "    '''1)Selects random frame in video\n",
    "    2) Extracts face from frame\n",
    "    3) Applies random transformations to image\n",
    "    4) Saves the image as png file.'''\n",
    "\n",
    "    frame = face_detector.random_frame_selector(source)\n",
    "    face = face_detector.face_cropper(frame)\n",
    "    \n",
    "    face = data_transforms(face)\n",
    "\n",
    "    rand_file_name = ''.join(random.choice(string.ascii_letters) for _ in range(10))\n",
    "\n",
    "    face.save(f'./images/{label_type}/{rand_file_name}.png', 'PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function over the video 3 times to extract 3 frames from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n",
      "No faces found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for real images\n",
    "for source in vll_real:\n",
    "    \n",
    "    for _ in range(2):\n",
    "        \n",
    "        save_cropped_image(source, 'real')\n",
    "        \n",
    "for source in vll_fake:\n",
    "    \n",
    "    for _ in range(2):\n",
    "        \n",
    "        save_cropped_image(source, 'fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
